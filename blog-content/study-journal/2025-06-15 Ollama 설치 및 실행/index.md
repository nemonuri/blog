---
alias: install-ollama-and-run
---

# Ollama ì„¤ì¹˜ ë° ì‹¤í–‰

## í•™ìŠµ ëª©í‘œ

1. Ollama ë¥¼ ì„¤ì¹˜í•˜ê³  ê°„ë‹¨í•œ AI ì±„íŒ…ì„ í•´ ë³¸ë‹¤.
2. Ollama ì˜ ì—¬ëŸ¬ê°€ì§€ ì„¤ì •ì— ëŒ€í•´ ì•Œì•„ë³¸ë‹¤.
3. Ollama ì˜ ì—¬ëŸ¬ê°€ì§€ ëª…ë ¹ì–´ì— ëŒ€í•´ ì•Œì•„ë³¸ë‹¤.

## Ollama ë€?

- [ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)](https://en.wikipedia.org/wiki/Large_language_model)ì„ ê°œì¸ìš© ì»´í“¨í„°, ì¦‰ ë¡œì»¬ì—ì„œë„ ì‹¤í–‰í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” í”„ë¡œê·¸ë¨.
- [ê³µì‹ í™ˆí˜ì´ì§€](https://ollama.com/)ì—ì„œ ì„¤ì¹˜ í”„ë¡œê·¸ë¨ì„ ë‹¤ìš´ë°›ì„ ìˆ˜ ìˆë‹¤.

## Ollama Windows ì„¤ì¹˜ ê²½ë¡œ

- Windows OS ì—ì„œ, ê¸°ë³¸ ì„¤ì¹˜ ê²½ë¡œëŠ” `%LOCALAPPDATA%\Programs\Ollama` ì´ë‹¤.
- ì„¤ì¹˜ í”„ë¡œê·¸ë¨(OllamaSetup.exe)ì„ ë‹¤ìŒê³¼ ê°™ì´ ì‹¤í–‰í•˜ë©´, ì„¤ì¹˜ ê²½ë¡œë¥¼ ë³€ê²½í•  ìˆ˜ ìˆë‹¤.
```pwsh
OllamaSetup.exe /DIR="d:\some\location"
```

## Ollama Windows ì„œë²„ ì‹¤í–‰

### ë°©ë²•1. ë°”ë¡œ ì‹¤í–‰

1. `ollama app.exe` ë¥¼ ì‹¤í–‰í•œë‹¤
2. Ollama ì„œë²„ê°€ ì‹¤í–‰ì¤‘ì¸ ê²ƒì„ í™•ì¸í•œë‹¤.
  - ![image1](image/image1.png) 

### ë°©ë²•2. ì»¤ë§¨ë“œ ì‰˜ì—ì„œ ì‹¤í–‰

1. ì»¤ë§¨ë“œ ì‰˜ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰
```pwsh
PS > ./ollama.exe serve
```

2. Ollama ì„œë²„ê°€ ì‹¤í–‰ì¤‘ì¸ ê²ƒì„ í™•ì¸
  - ì•„ì´ì½˜ ëŒ€ì‹ , ì¶œë ¥ ë¡œê·¸ë¡œ.
```log
time=2025-06-19T10:29:19.000+09:00 level=INFO source=routes.go:1234 msg="server config" env="map[CUDA_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://127.0.0.1:11434 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:(ìƒëµ) OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:0 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES:]"
time=2025-06-19T10:29:19.012+09:00 level=INFO source=images.go:479 msg="total blobs: 16"
time=2025-06-19T10:29:19.012+09:00 level=INFO source=images.go:486 msg="total unused blobs removed: 0"
time=2025-06-19T10:29:19.012+09:00 level=INFO source=routes.go:1287 msg="Listening on 127.0.0.1:11434 (version 0.9.0)"
time=2025-06-19T10:29:19.012+09:00 level=INFO source=gpu.go:217 msg="looking for compatible GPUs"
time=2025-06-19T10:29:19.012+09:00 level=INFO source=gpu_windows.go:167 msg=packages count=1
time=2025-06-19T10:29:19.012+09:00 level=INFO source=gpu_windows.go:183 msg="efficiency cores detected" maxEfficiencyClass=1
time=2025-06-19T10:29:19.013+09:00 level=INFO source=gpu_windows.go:214 msg="" package=0 cores=16 efficiency=8 threads=24
time=2025-06-19T10:29:19.166+09:00 level=INFO source=gpu.go:319 msg="detected OS VRAM overhead" id=GPU-00a81de9-e84d-464d-6918-dc6b26705ca9 library=cuda compute=8.6 driver=12.6 name="NVIDIA GeForce RTX 3060 Ti" overhead="498.8 MiB"
time=2025-06-19T10:29:19.169+09:00 level=INFO source=types.go:130 msg="inference compute" id=GPU-00a81de9-e84d-464d-6918-dc6b26705ca9 library=cuda variant=v12 compute=8.6 driver=12.6 name="NVIDIA GeForce RTX 3060 Ti" total="8.0 GiB" available="7.0 GiB"
```

ì¶œë ¥ ë¡œê·¸ë¡œë¶€í„°, ì—¬ëŸ¬ í™˜ê²½ ë³€ìˆ˜ë¥¼ í†µí•´ Ollama ì„œë²„ë¥¼ ì„¤ì •í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.

### Ollama ì„œë²„ ì„¤ì • ê´€ë ¨ í™˜ê²½ ë³€ìˆ˜

1. ë‹¤ìŒì„ ì‹¤í–‰í•´ ë„ì›€ë§ í™•ì¸
```pwsh
PS > ./ollama.exe serve --help
```

2. ê²°ê³¼

 | Environment Variables | Discription |
 | --- | --- |
 | OLLAMA_DEBUG | Show additional debug information (e.g. OLLAMA_DEBUG=1) | 
 | OLLAMA_HOST | IP Address for the ollama server (default 127.0.0.1:11434) | 
 | OLLAMA_KEEP_ALIVE | The duration that models stay loaded in memory (default "5m") | 
 | OLLAMA_MAX_LOADED_MODELS | Maximum number of loaded models per GPU | 
 | OLLAMA_MAX_QUEUE | Maximum number of queued requests | 
 | OLLAMA_MODELS | The path to the models directory | 
 | OLLAMA_NUM_PARALLEL | Maximum number of parallel requests | 
 | OLLAMA_NOPRUNE | Do not prune model blobs on startup | 
 | OLLAMA_ORIGINS | A comma separated list of allowed origins | 
 | OLLAMA_SCHED_SPREAD | Always schedule model across all GPUs | 
 | OLLAMA_FLASH_ATTENTION | Enabled flash attention | 
 | OLLAMA_KV_CACHE_TYPE | Quantization type for the K/V cache (default: f16) | 
 | OLLAMA_LLM_LIBRARY | Set LLM library to bypass autodetection | 
 | OLLAMA_GPU_OVERHEAD | Reserve a portion of VRAM per GPU (bytes) | 
 | OLLAMA_LOAD_TIMEOUT | How long to allow model loads to stall before giving up (default "5m") | 

#### Ollama ì„œë²„ ê¸°ë³¸ ì£¼ì†Œ (OLLAMA_HOST)
`127.0.0.1:11434`

## Ollama ì±„íŒ… í´ë¼ì´ì–¸íŠ¸ ì‹¤í–‰

1. ë‹¤ìŒì„ ì‹¤í–‰í•œë‹¤.
```pwsh
PS > ./ollama.exe run ëª¨ë¸_ì‹ë³„ì
```

2. `ëª¨ë¸_ì‹ë³„ì` ì— í•´ë‹¹í•˜ëŠ” ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ë‹¤ë©´, í•´ë‹¹ ëª¨ë¸ì„ [`ê³µì‹ ì €ì¥ì†Œ`](https://ollama.com/search)ì—ì„œ ë‹¤ìš´ë°›ì•„ ë“±ë¡í•˜ëŠ” ì‘ì—…ì´ ë¨¼ì € ì§„í–‰ëœë‹¤.
3. 2.ê°€ ì™„ë£Œë˜ë©´, ì±„íŒ… í´ë¼ì´ì–¸íŠ¸ê°€ ì‹œì‘ëœë‹¤.

### ì—¬ëŸ¬ ì¤„ ì…ë ¥í•˜ê¸°

- ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ `"""`ë¡œ ê°ì‹¸ë©´ ëœë‹¤.

```
>>> """Hello,
... world!
... """
I'm a basic program that prints the famous "Hello, world!" message to the console.
```

### Ollama ëª¨ë¸ ê´€ë ¨ ëª…ë ¹ì–´

1. ëª¨ë¸ ë¯¸ë¦¬ ë‹¤ìš´ë°›ì•„ ë“±ë¡í•˜ê¸°
```pwsh
./ollama.exe pull ëª¨ë¸_ì‹ë³„ì
```

2. ë¡œì»¬ì— ë“±ë¡ëœ ëª¨ë¸ ëª©ë¡ í™•ì¸í•˜ê¸°
```pwsh
./ollama.exe list
```

## Ollama ì±„íŒ… ì‹¤í–‰ ì˜ˆì‹œ

1. `qwen3:0.6b` ëª¨ë¸ ì‹¤í–‰
```pwsh
PS > ollama run qwen3:0.6b
```

```
>>> ì•ˆë…•? í•œêµ­ë§ í•  ì¤„ ì•Œì•„?
Thinking...
Okay, the user is asking in Korean, so I need to respond in Korean. Let me check the message again. They said "ì•ˆë…•? í•œêµ­ë§ í•  ì¤Œ?" which
translates to "Hello? Do you know Korean?" So the user wants to confirm if they can speak Korean.

I should respond in Korean, so I need to make sure I'm using the correct terms. "ì•ˆë…•" is "Hello," and "í•œêµ­ë§" is "Korean." So the response
should be "ì•ˆë…•í•˜ì„¸ìš”. Korean ë§ì„ ì˜ ì•Œê³  ìˆì–´ìš”!" which means "Hello! I know Korean well."

I should also make sure the tone is friendly and helpful. The user might be trying to check if I can speak Korean, so providing a clear and
positive response is important. Let me double-check the translation to ensure accuracy. Yes, that looks right. Now, put it all together in
Korean.
...done thinking.

ì•ˆë…•í•˜ì„¸ìš”. Korean ë§ì„ ì˜ ì•Œê³  ìˆì–´ìš”! ğŸ˜Š

>>> """ë‹¤ìŒ ë‚´ìš©ì„ ë¬¸êµ¬ í•˜ë‚˜ë¡œ í‘œí˜„í•˜ë¼.
... ```
... 1. 'í•„ë“œì˜ í¬ê¸°(fieldSize)'ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ëŠ”ë‹¤.
... 2. í•„ë“œì— ëª¬ìŠ¤í„°ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
... 3. 'ìƒì„±ëœ ëª¬ìŠ¤í„° ê°œì²´ ë¦¬ìŠ¤íŠ¸'ë¥¼ ë°˜í™˜í•œë‹¤.
... ```
... """
Thinking...
Okay, let's see. The user wants me to express three tasks into a single sentence using Korean. The tasks are:

1. "í•„ë“œì˜ í¬ê¸°(fieldSize)"ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ëŠ”ë‹¤.
2. í•„ë“œì— ëª¬ìŠ¤í„°ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
3. "ìƒì„±ëœ ëª¬ìŠ¤í„° ê°œì²´ ë¦¬ìŠ¤íŠ¸"ë¥¼ ë°˜í™˜í•œë‹¤.

First, I need to make sure each task is included in a single sentence. Let me think about how to combine them. Maybe start with the first
task, then mention the second, and end with the third.

So, "í•„ë“œì˜ í¬ê¸°(fieldSize)ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ê³ , í•„ë“œì— ëª¬ìŠ¤í„°ë“¤ì„ ìƒì„±í•˜ê³ , ìƒì„±ëœ ëª¬ìŠ¤í„° ê°œì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤." That seems good. Let me
check if there's a better way. Maybe "í•„ë“œì— ëª¬ìŠ¤í„°ë¥¼ ìƒì„±í•˜ê³ , ìƒì„±ëœ ëª¬ìŠ¤í„° ê°œì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤." But the original tasks are
in Korean, so keeping them exact is better. Also, ensuring the order makes sense in a single sentence. Yeah, that should work.
...done thinking.

í•„ë“œì˜ í¬ê¸°(fieldSize)ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ê³ , í•„ë“œì— ëª¬ìŠ¤í„°ë¥¼ ìƒì„±í•˜ê³ , ìƒì„±ëœ ëª¬ìŠ¤í„° ê°œì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
```

### ê°œì¸ì ì¸ ì†Œê°

- ì—„ì²­ ë¹ ë¥´ê³  ê°€ë³ë‹¤! ìš©ëŸ‰ë„ ì‘ê³ . ê³„ì‚° ë¶€ë‹´ë„ ì ê³ .
- ê²Œë‹¤ê°€ 'Thinking...' ê¸°ëŠ¥ë„ ê½¤ ë§ˆìŒì— ë“ ë‹¤!
- ë¬¼ë¡  ë¬´ê±°ìš´ ëª¨ë¸ë„ ìˆë‹¤...ëª¨ë¸ë§ˆë‹¤ ì¥ë‹¨ì ì´ ìˆìœ¼ë‹ˆ ì˜ ì„ íƒí•  ê²ƒ.

## ì°¸ê³ ìë£Œ

- [ollama ê³µì‹ Github repository](https://github.com/ollama/ollama)
- [ollama ëª¨ë¸ ê³µì‹ ì €ì¥ì†Œ](https://ollama.com/search)
- [Ollama Windows ê°€ì´ë“œ](https://github.com/ollama/ollama/blob/main/docs/windows.md)